## Problem solving

A few problems arose in the process of refactoring caused by the different approach that CQRS takes. The following lines describe the problems and the steps taken to solving them.

### Dealing with consistency issues

One problem was encountered when designing the file system in the new domain model, i.e. the files and folders structure and its behavior. In the original design, the file system model was achieved by the `File` and `Folder` Hibernate entities that referenced other entities of the same type to form a tree of relationships. These entities were supposed to be refactored as well. 

By the definition, an aggregate is a set of related objects that represents a transaction boundary. This was considered in the refactoring of the entities. There are some business rules that had to be preserved when designing aggregates for the file system. The first one is the consistency of the delete operation on a folder, the second is the uniqueness of node name in a folder. These business rules could be upheld by modeling the file system as one big aggregate, containing folders and files in a tree hierarchy. However, the folders can be nested, and so the aggregate could grow very large. Loading such an aggregate with possibly thousands of objects would be incredibly resource-intensive and impossible to scale. In **reference needed**(https://vaughnvernon.co/wordpress/wp-content/uploads/2014/10/DDD_COMMUNITY_ESSAY_AGGREGATES_PART_1.pdf )... it is advised to make aggregates small. Also, it provides some solutions to consistency issues. So the folders and files were designed as self-contained aggregates. Similarly to the original entities, the two new aggregates, `Folder` and `File`, share some common functionality that was abstracted to a parent class (`AbstractNodeAggregateRoot`).

#### Node name uniqueness

As the individual instances of the `Folder` aggregate have no access to the names of the contained files and subfolders, it was needed to find another way how to ensure uniqueness of node names in a folder. To resolve this issue, a special read model is built by events to store only identifiers of nodes and their names and parent folders. This model is queried just before creating a new child node, renaming a node, or moving a node to other folder to ensure uniqueness of the node name in that particular folder. Read model is kept in sync accordingly with the changes made to the nodes. There is no consistency issue here, because building the read model, in this case, happens in the same transaction as persisting changes of an aggregate instance.

#### Folder deletion

The other problem was the delete operation on a folder. In the original design, when a folder was deleted, it recursively deleted all the child folders and files in one transaction via Hibernate's support of collections. Now, that a folder is represented as an aggregate which doesn't hold references to other child folders or files, it wasn't so straightforward to recursively delete child nodes. This issue was not easy to solve without a lot of experience with CQRS design. However, it then occurred that a saga (or in this case, a process manager) could be of use. This idea was validated by CQRS practitioners in **citation needed**(http://programmers.stackexchange.com/questions/298462/deleting-subtrees-in-hierarchical-agreggates).

The basic principle is that the process manager (called `FolderDeletionSaga` in the code) coordinates the deletion of multiple aggregate instances representing the child nodes of a folder. It is started by publishing event `FolderDeletionStartedEvent` by the `Folder` aggregate instance, which marks the beginning of the deletion process. Using the same consistent read model as above, it initially queries for the children of the folder to delete. For each child node (folder or file) it sends a new command to the respective aggregate instance to delete itself first. File aggregate instances are deleted trivially. For each child folder, however, a new process manager is recursively instantiated to manage the deletion process of that folder. When all the nodes are deleted from a folder, i.e. the folder is empty, the saga managing the folder deletion sends one final internal command to the folder aggregate instance to mark it deleted. When the top saga instance, that initiated the recursive deletion process, is reached, the process is finished. Because the sagas are driven by events published by the aggregates, it is very easy to track the state of the deletion process.

#### Privacy issues

In Integration Portal, the system is prevented from unauthorized access by requiring authentication. To successfully authenticate, a user needs to provide the correct username (e-mail address in new user management) and password. In return, an access token is sent to the client, which needs be specified in every subsequent request. Users' passwords should be handled very carefully, if anybody breaks into the application database, they must not be able to get the raw passwords. Usually, passwords are not stored in the database directly, but rather they are hashed.

Because Event Sourcing instructs to save state changes as events to persistent storage, this should also be applied when setting or changing a users' passwords. However, events that store passwords should be considered a privacy (and security) issue, even though the passwords are hashed. If the event store database is compromised, all the events about setting the users' passwords could be in risk of exploitation, including the old users' passwords that changed in the past. For this reason, events do not store passwords (or their hash codes) at all, and so passwords are excluded from the event-sourced state. A hashed password is saved into the read-side database in a command handler, outside of aggregates or event handlers. A domain event notifying about a password change still exists, but it does not carry password data in any form.

This exception has an impact on almost all the benefits that Event Sourcing provides, but it is crucial for user privacy and security. On the other hand, let's note that passwords are not needed for any other purpose than authentication in most cases. This situation was a great example of when Event Sourcing is unnecessary for some parts of a system. It is fundamental to point out again, that the Event Sourcing pattern, as well as any other, is not all or nothing and should be used in appropriate places only.