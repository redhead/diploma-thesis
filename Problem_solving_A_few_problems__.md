## Problem solving

A few problems arose in the process of refactoring caused by the different approach that CQRS takes. The following lines describe the problems and the steps taken to solving them.

### Dealing with consistency issues

One problem was encountered when designing the file system in the new domain model, i.e. the files and folders structure and its behavior. In the original design, the file system model was achieved by Hibernate file and folder entities that referenced other entities of the same type to form a tree of relationships. These entities were supposed to be refactored as well. 

By the definition, an aggregate is a set of related objects that represents a transaction boundary. This was considered in the refactoring of the entities. There are some business rules that had to be preserved when designing aggregates for the file system. The first one is consistency of the delete operation on a folder, the second is uniqueness of node name in a folder. These business rules could be uphold by modeling the file system as one big aggregate, containing folders and files in tree hierarchy. However, the folders can be nested, and so the aggregate could grow very large. Loading such an aggregate with possibly thousands of objects would be incredibly resource intensive and impossible to scale. In **reference needed**(https://vaughnvernon.co/wordpress/wp-content/uploads/2014/10/DDD_COMMUNITY_ESSAY_AGGREGATES_PART_1.pdf )... it is advised to make aggregates small, also it provides some solutions to consistency issues. So the folders and files were designed as self-contained aggregates. Similarly to the original entities, the two new aggregates, `Folder` and `File`, share some common functionality that was abstracted to a parent class (`AbstractNodeAggregateRoot`).

#### Node name uniqueness

As the individual instances of the `Folder` aggregate have no access to the names of the contained files and subfolders, it was needed to find another way how to ensure uniqueness of node names in a folder. To resolve this issue, a special read model is built by events to store only identifiers of nodes and their names and parent folders. This model is queried just before creating a new child node, renaming a node, or moving a node to other folder to ensure uniqueness of the node name in that particular folder. Read model is kept in sync accordingly with the changes made to the nodes. There is no consistency issue here, because building the read model, in this case, happens in the same transaction as persisting changes of an aggregate instance.

#### Folder deletion

The other problem was the delete operation on a folder. In the original design, when a folder was deleted, it recursively deleted all the child folders and files in one transaction via Hibernate's support of collections. Now, that a folder is represented by an aggregate which doesn't hold references to other child folders or files, it wasn't easy to do the recursive deletion of child nodes. This issue was not easy to solve without a lot of experience with CQRS design. But it then occurred that a saga (or in this case, a process manager) could be of use. This idea was validated by CQRS practitioners in **citation needed**(http://programmers.stackexchange.com/questions/298462/deleting-subtrees-in-hierarchical-agreggates).

The basic principle is that the process manager (called `FolderDeletionSaga` in the code) coordinates the deletion of multiple aggregate instances representing the child nodes of a folder. It is started by publishing event `FolderDeletionStartedEvent` by the `Folder` aggregate instance, which marks the beginning of the deletion process. Using the same consistent read model as above, it initially queries for the children of the folder to delete. For each child node (folder or file) it sends a new command to the respective aggregate instance to delete itself first. File aggregate instances are deleted trivially. For each child folder, however, a new process manager is recursively instantiated to manage the deletion process of that folder. When all the nodes are deleted from a folder, i.e. the folder is empty, the saga managing the folder deletion sends one final internal command to the folder aggregate instance to mark it deleted. When the top saga instance, that initiated the recursive deletion process, is reached, the process is finished. Because the sagas are driven by events published by the aggregates, it is very easy to track the state of the deletion process.

